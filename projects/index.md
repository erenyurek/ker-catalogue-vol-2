---
layout: page
title: Projects
subtitle: What I'm working on
show-avatar: false
---

## Network-level validation
<p style="display:inline-block">
<img src="/assets/img/validation_environment.png" style="float:right" alt="" width="400"/>
Modeling and the simulation of the activity in neuronal networks is an essential part of modern neuroscience and represents a powerful vehicle to combine insights from experiments and theory into a coherent understanding of brain function.
The only measure to assess how much trust we can place in a given model is how well it can predict the biological reality it aims to describe. Validation testing formalizes the comparison between measured and simulated data and quantifies their similarity. The resulting test scores characterize the model and determine its validity with respect to predictions concerning the experimental reference. However, it is sometimes useful to directly compare two models by means analogous to validation testing. Such direct comparisons are not constrained by the scarcity and specificity of experimental data and thus allow for more thorough evaluation of the two models. In contrast to validation, direct comparisons between two models are not able to determine the descriptive power of a model regarding its reference to reality. They can, however, be greatly beneficial in evaluating the modelâ€™s consistency, robustness with respect to parameter variation, and directed improvements in the model development process.
In either scenario, several aspects must be considered. Any validation test only considers a specific statistic of a certain aspect of a finitely sampled data set. Therefore, in order to gain a more complete and less biased evaluation, it is necessary to apply multiple validation tests, taking into account different aspects and statistical measures. For example, for a neural network model the dynamics on the single-cell and network activity level are not trivially related, and thus should be regarded individually. Additionally, any test score should be quantitative, reproducible, and ideally based on open, standardized software tools.
</p>
* Python package [NetworkUnit](https://github.com/INM-6/NetworkUnit)
* Interactive tutorial [notebook](https://gke.mybinder.org/v2/gh/INM-6/NetworkUnit/master?filepath=examples%2Findex.ipynb)
* [Validation paper](https://doi.org/10.3389/fninf.2018.00090)
* [Verification paper](https://doi.org/10.3389/fninf.2018.00081)


Related tags: [Validation](../tags/#validation)

<!-- ![](/assets/rasterplot.png)
![](/assets/validation_results.png) -->

## Slow waves analysis pipeline
*[to be filled]*
## Eigenangles
*[to be filled]*
## Dynamics of cortical LFP waves and spikes
*[to be filled]*
## Links to related projects

<div style="content: ''; clear: both; display: table;">
<a href="https://elephant.readthedocs.io/en/latest/" style="float: left; width: 20%; padding: 5px">
<img src="https://elephant.readthedocs.io/en/latest/_static/elephant_logo_sidebar.png" alt="Elephant" style="padding-top: 10px;">
</a>
&nbsp; &nbsp; &nbsp; &nbsp;
<a href="https://neo.readthedocs.io/en/latest/" style="float: left; width: 20%; padding: 5px">
<img src="https://neo.readthedocs.io/en/latest/_images/neologo.png" alt="Neo" style="padding-top: 40px;">
</a>
&nbsp; &nbsp; &nbsp; &nbsp;
<a href="https://github.com/scidash/sciunit" style="float: left; width: 20%; padding: 5px">
<img src="https://raw.githubusercontent.com/scidash/assets/master/logos/SciUnit/sci-unit-square-small.png" alt="SciUnit" style="padding-left: 10px; padding-right: 10px;">
</a>
&nbsp; &nbsp; &nbsp; &nbsp;
<a href="https://wiki.ebrains.eu/bin/view/Main/" style="float: left; width: 20%; padding: 5px">
<img src="/assets/img/ebrains_logo.png" alt="EBRAINS" style="padding-left: 15px; padding-right:15px;">
</a>
</div>

<!--# Side projects
    workflow management
    real-time collaborative online html editor-->
